{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# RAG Demo - Reproducible End-to-End\n",
                "\n",
                "This notebook demonstrates the complete RAG pipeline:\n",
                "1. Load sample dataset\n",
                "2. Compute embeddings\n",
                "3. Build FAISS index\n",
                "4. Run sample queries\n",
                "5. Evaluate results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies (if running in Colab)\n",
                "!pip install sentence-transformers faiss-cpu pandas numpy matplotlib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sentence_transformers import SentenceTransformer\n",
                "import faiss\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Sample Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load documents\n",
                "df = pd.read_csv('../data/sample/documents.csv')\n",
                "print(f\"Loaded {len(df)} documents\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Compute Embeddings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load embedding model\n",
                "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
                "print(f\"Model: {model}\")\n",
                "print(f\"Embedding dimension: {model.get_sentence_embedding_dimension()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Encode documents\n",
                "texts = df['text'].tolist()\n",
                "embeddings = model.encode(texts, show_progress_bar=True)\n",
                "print(f\"Embeddings shape: {embeddings.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Build FAISS Index"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create FAISS index\n",
                "dimension = embeddings.shape[1]\n",
                "index = faiss.IndexFlatL2(dimension)\n",
                "index.add(np.array(embeddings, dtype=np.float32))\n",
                "print(f\"Index contains {index.ntotal} vectors\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Run Sample Queries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def search(query, k=5):\n",
                "    \"\"\"Search for top-k similar documents\"\"\"\n",
                "    query_embedding = model.encode([query])[0]\n",
                "    query_embedding = np.array([query_embedding], dtype=np.float32)\n",
                "    \n",
                "    distances, indices = index.search(query_embedding, k)\n",
                "    \n",
                "    results = []\n",
                "    for idx, dist in zip(indices[0], distances[0]):\n",
                "        results.append({\n",
                "            'title': df.iloc[idx]['title'],\n",
                "            'text': df.iloc[idx]['text'],\n",
                "            'distance': float(dist),\n",
                "            'similarity': 1 / (1 + float(dist))  # Convert distance to similarity\n",
                "        })\n",
                "    \n",
                "    return results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Query 1: What is RAG?\n",
                "query1 = \"What is RAG?\"\n",
                "results1 = search(query1, k=3)\n",
                "\n",
                "print(f\"Query: {query1}\\n\")\n",
                "for i, result in enumerate(results1, 1):\n",
                "    print(f\"{i}. {result['title']} (similarity: {result['similarity']:.3f})\")\n",
                "    print(f\"   {result['text'][:100]}...\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Query 2: How do agents work?\n",
                "query2 = \"How do agents work?\"\n",
                "results2 = search(query2, k=3)\n",
                "\n",
                "print(f\"Query: {query2}\\n\")\n",
                "for i, result in enumerate(results2, 1):\n",
                "    print(f\"{i}. {result['title']} (similarity: {result['similarity']:.3f})\")\n",
                "    print(f\"   {result['text'][:100]}...\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Query 3: OpenRouter API\n",
                "query3 = \"Tell me about OpenRouter\"\n",
                "results3 = search(query3, k=3)\n",
                "\n",
                "print(f\"Query: {query3}\\n\")\n",
                "for i, result in enumerate(results3, 1):\n",
                "    print(f\"{i}. {result['title']} (similarity: {result['similarity']:.3f})\")\n",
                "    print(f\"   {result['text'][:100]}...\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Visualize Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize similarity scores\n",
                "queries = [query1, query2, query3]\n",
                "all_results = [results1, results2, results3]\n",
                "\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "for idx, (query, results) in enumerate(zip(queries, all_results)):\n",
                "    titles = [r['title'][:20] for r in results]\n",
                "    similarities = [r['similarity'] for r in results]\n",
                "    \n",
                "    axes[idx].barh(titles, similarities, color='skyblue')\n",
                "    axes[idx].set_xlabel('Similarity Score')\n",
                "    axes[idx].set_title(f\"Query: {query[:30]}...\")\n",
                "    axes[idx].set_xlim(0, 1)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Save Index (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save FAISS index\n",
                "import os\n",
                "os.makedirs('../data/sample_embeddings', exist_ok=True)\n",
                "faiss.write_index(index, '../data/sample_embeddings/index.faiss')\n",
                "print(\"✓ Index saved to ../data/sample_embeddings/index.faiss\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "This notebook demonstrated:\n",
                "- ✅ Loading a sample dataset\n",
                "- ✅ Computing embeddings with sentence-transformers\n",
                "- ✅ Building a FAISS index for efficient search\n",
                "- ✅ Running semantic search queries\n",
                "- ✅ Visualizing similarity scores\n",
                "\n",
                "Next steps:\n",
                "- Integrate with LLM for response generation\n",
                "- Add re-ranking for improved relevance\n",
                "- Scale to larger datasets"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}